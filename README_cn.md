[ä¸­æ–‡] | [English](README.md)

# LLM-Estimate

å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½ä¼°ç®—å·¥å…· - ä¼°ç®—LLMåœ¨ä¸åŒç¡¬ä»¶é…ç½®ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ æ”¯æŒå¤šç§ä¸»æµLLMæ¨¡å‹ï¼ˆQwenã€MoEç­‰ï¼‰
- ğŸ’» ç»Ÿä¸€åŠ é€Ÿå™¨æŠ½è±¡ï¼ˆGPUã€CPUã€TPUã€SOCç­‰ï¼‰
- ğŸ“Š ä¼°ç®—å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆTTFTã€TPOTã€ååé‡ã€å†…å­˜ä½¿ç”¨ï¼‰
- ğŸ”§ æ“ä½œçº§åˆ«è¯¦ç»†åˆ†æå’Œç“¶é¢ˆè¯†åˆ«
- ğŸ“‹ æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆè¡¨æ ¼ã€JSONã€CSVï¼‰
- ğŸ–¥ï¸ å‘½ä»¤è¡Œå·¥å…·å’ŒPython API
- âš¡ ä¸“æ³¨ç®—åŠ›ï¼ˆFLOPSï¼‰å’Œå†…å­˜å¸¦å®½æ ¸å¿ƒæŒ‡æ ‡

## æ ¸å¿ƒæ¦‚å¿µ

æœ¬é¡¹ç›®å°†GPUã€CPUã€TPUã€SOCç­‰è®¡ç®—è®¾å¤‡ç»Ÿä¸€æŠ½è±¡ä¸º**åŠ é€Ÿå™¨**ï¼Œä¸å†åŒºåˆ†è®¾å¤‡ç±»å‹ï¼Œåªå…³æ³¨ï¼š
- **ç®—åŠ›**: è®¡ç®—èƒ½åŠ›ï¼ˆTFLOPSï¼‰
- **å†…å­˜å¸¦å®½**: å­˜å‚¨å¸¦å®½ï¼ˆGB/sï¼‰
- **å†…å­˜å®¹é‡**: å¯ç”¨å†…å­˜ï¼ˆGBï¼‰

è¿™ç§ç»Ÿä¸€æŠ½è±¡ç®€åŒ–äº†ç¡¬ä»¶é…ç½®ï¼Œä½¿æ€§èƒ½ä¼°ç®—æ›´åŠ ç›´è§‚å’Œå‡†ç¡®ã€‚

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/zhangwm/llm-estimate.git
cd llm-estimate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¯é€‰ï¼šå®‰è£…é¡¹ç›®ï¼ˆç”¨äºå…¨å±€å‘½ä»¤ï¼‰
pip install -e .
```

### è¿è¡Œæ–¹å¼

#### æ–¹å¼1: ç›´æ¥è¿è¡Œï¼ˆæ¨èï¼Œæ— éœ€å®‰è£…ï¼‰

```bash
# ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„å…¥å£è„šæœ¬
python3 llm_estimate.py --help

# æˆ–è€…ç»™è„šæœ¬æ‰§è¡Œæƒé™åç›´æ¥è¿è¡Œ
chmod +x llm_estimate.py
./llm_estimate.py --help
```

#### æ–¹å¼2: æ¨¡å—æ–¹å¼è¿è¡Œ

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡ŒCLIæ¨¡å—
python3 -m llm_estimate.cli --help

# æˆ–è€…è¿è¡Œæ¨¡å—å†…çš„main.py
python3 llm_estimate/main.py --help
```

#### æ–¹å¼3: å®‰è£…åå…¨å±€å‘½ä»¤

```bash
# å…ˆå®‰è£…é¡¹ç›®
pip install -e .

# ç„¶åå¯ä»¥å…¨å±€ä½¿ç”¨
llm-estimate --help
```

**æ³¨æ„**: æ–¹å¼1æ˜¯æœ€ç®€å•çš„æ–¹æ³•ï¼Œåªéœ€è¦å…‹éš†é¡¹ç›®å’Œå®‰è£…ä¾èµ–å³å¯è¿è¡Œï¼Œæ— éœ€å®‰è£…åŒ…ã€‚

### åŸºæœ¬ä½¿ç”¨

#### å‘½ä»¤è¡Œå·¥å…·

```bash
# ä¼°ç®—Qwen-8Båœ¨RTX-4090ä¸Šçš„æ€§èƒ½
python3 llm_estimate.py estimate --model qwen3-8b --accelerator rtx-4090

# æŒ‡å®šç²¾åº¦ã€æ‰¹æ¬¡å¤§å°å’Œåºåˆ—é•¿åº¦
python3 llm_estimate.py estimate --model qwen3-8b --accelerator rtx-4090 --precision fp16 --batch-size 4 --input-length 1024 --output-length 256

# è¯¦ç»†åˆ†æï¼ŒåŒ…å«æ“ä½œçº§åˆ«åˆ†è§£
python3 llm_estimate.py estimate --model qwen3-8b --accelerator rtx-4090 --verbose

# æ˜¾ç¤ºè¯¦ç»†çš„æ“ä½œåˆ†è§£
python3 llm_estimate.py estimate --model qwen3-8b --accelerator rtx-4090 --show-ops --top-ops 20 --detailed

# åˆ—å‡ºæ”¯æŒçš„æ¨¡å‹
python3 llm_estimate.py list-models

# åˆ—å‡ºæ”¯æŒçš„åŠ é€Ÿå™¨
python3 llm_estimate.py list-accelerators

# æŒ‰ç±»å‹ç­›é€‰åŠ é€Ÿå™¨
python3 llm_estimate.py list-accelerators --type gpu
python3 llm_estimate.py list-accelerators --type cpu

# è·¨ä¸åŒåºåˆ—é•¿åº¦çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
python3 llm_estimate.py benchmark --model qwen3-8b --accelerator rtx-4090 --input-lengths 512,1024,2048,4096 --output-lengths 128,256,512

# äº¤äº’å¼æ¨¡å¼
python3 llm_estimate.py interactive
```

#### Python API

```python
from llm_estimate import PerformanceEstimator, create_accelerator

# åˆ›å»ºä¼°ç®—å™¨
estimator = PerformanceEstimator()

# å•åŠ é€Ÿå™¨ä¼°ç®—
result = estimator.estimate(
    model_name="qwen3-8b",
    hardware_config={"accelerator": "rtx-4090"},
    model_config={"batch_size": 1, "precision": "fp16"}
)

print(f"ååé‡: {result['throughput_tokens_per_sec']:.1f} tokens/s")
print(f"å†…å­˜ä½¿ç”¨: {result['memory_usage_gb']:.2f} GB")
print(f"é¦–Tokenæ—¶é—´: {result['ttft_ms']:.1f} ms")
print(f"æ¯Tokenæ—¶é—´: {result['tpot_ms']:.1f} ms")
print(f"ç“¶é¢ˆ: {result['bottleneck']}")

# ç›´æ¥åˆ›å»ºåŠ é€Ÿå™¨
accelerator = create_accelerator("rtx-4090")
print(f"ç®—åŠ›: {accelerator.compute_capability_tflops} TFLOPS")
print(f"å†…å­˜å¸¦å®½: {accelerator.memory_bandwidth_gb_s} GB/s")
```

## é¡¹ç›®ç»“æ„

```
llm-estimate/
â”œâ”€â”€ llm_estimate/           # ä¸»è¦ä»£ç ç›®å½•
â”‚   â”œâ”€â”€ models/            # æ¨¡å‹ç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ hardware/          # ç¡¬ä»¶ç®¡ç†æ¨¡å—ï¼ˆç»Ÿä¸€åŠ é€Ÿå™¨ï¼‰
â”‚   â”œâ”€â”€ estimator/         # ä¼°ç®—å¼•æ“æ¨¡å—
â”‚   â”œâ”€â”€ config/            # å…¨å±€é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ utils/             # å·¥å…·æ¨¡å—
â”‚   â””â”€â”€ cli/               # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ tests/                 # æµ‹è¯•æ¨¡å—
â”œâ”€â”€ data/                  # æ•°æ®ç›®å½•
â”œâ”€â”€ docs/                  # æ–‡æ¡£ç›®å½•
â””â”€â”€ scripts/               # è„šæœ¬ç›®å½•
```

## æ”¯æŒçš„æ¨¡å‹

### Qwenç³»åˆ—
- **qwen3-8b**: 8Bå‚æ•°ï¼Œ36å±‚ï¼Œ40Kä¸Šä¸‹æ–‡ï¼ŒGQAæ¶æ„

### æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰
- **qwen3-235b-a22b**: 235Bæ€»å‚æ•°ï¼Œ94å±‚ï¼Œ128ä¸ªä¸“å®¶ï¼Œæ¯tokenæ¿€æ´»8ä¸ªä¸“å®¶

## æ”¯æŒçš„åŠ é€Ÿå™¨

### GPUåŠ é€Ÿå™¨
- **RTX-4090**: 660 TFLOPSï¼Œ1008 GB/sï¼Œ24 GBæ˜¾å­˜
- **H100-80GB**: 1979 TFLOPSï¼Œ2039 GB/sï¼Œ80 GBæ˜¾å­˜

### CPUåŠ é€Ÿå™¨
- **i9-13900K**: 1.2 TFLOPSï¼Œ77 GB/sï¼Œæœ€å¤§128 GBå†…å­˜
- **Ryzen-9-7950X**: 1.1 TFLOPSï¼Œ83 GB/sï¼Œæœ€å¤§128 GBå†…å­˜

### Apple Silicon
- **M2-Ultra**: 27.2 TFLOPSï¼Œ800 GB/sï¼Œ192 GBç»Ÿä¸€å†…å­˜

### Google TPU
- **TPU-v4**: 275 TFLOPSï¼Œ1200 GB/sï¼Œ32 GBå†…å­˜

## æ ¸å¿ƒåŠŸèƒ½

### æ“ä½œçº§åˆ«åˆ†æ
- è¯¦ç»†åˆ†è§£Transformeræ“ä½œï¼ˆæ³¨æ„åŠ›ã€FFNã€å½’ä¸€åŒ–ç­‰ï¼‰
- æ¯ä¸ªæ“ä½œçš„FLOPSå’Œå†…å­˜å¸¦å®½åˆ†æ
- ç“¶é¢ˆè¯†åˆ«å’Œä¼˜åŒ–å»ºè®®

### æ€§èƒ½æŒ‡æ ‡
- **TTFT (Time To First Token)**: é¦–Tokenç”Ÿæˆæ—¶é—´
- **TPOT (Time Per Output Token)**: åç»­Tokenå¹³å‡ç”Ÿæˆæ—¶é—´
- **ååé‡**: æ¯ç§’å¤„ç†çš„æ€»Tokenæ•°
- **å†…å­˜ä½¿ç”¨**: æ¨¡å‹å’Œæ¿€æ´»å€¼å†…å­˜éœ€æ±‚

### é«˜çº§CLIé€‰é¡¹
- `--verbose`: å¯ç”¨è¯¦ç»†çš„æ“ä½œçº§åˆ«åˆ†æ
- `--show-ops`: æ˜¾ç¤ºæ“ä½œåˆ†è§£
- `--top-ops N`: æ˜¾ç¤ºå‰Nä¸ªæœ€è€—æ—¶çš„æ“ä½œ
- `--detailed`: æ˜¾ç¤ºåŒ…æ‹¬ç“¶é¢ˆçš„ç»¼åˆåˆ†æ
- `--format`: ä»¥è¡¨æ ¼ã€JSONæˆ–CSVæ ¼å¼è¾“å‡º

## å¼€å‘

### ç¯å¢ƒè®¾ç½®

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œæµ‹è¯•
pytest

# ä»£ç æ ¼å¼åŒ–
black llm_estimate/

# ç±»å‹æ£€æŸ¥
mypy llm_estimate/
```

### æ·»åŠ æ–°æ¨¡å‹

1. åœ¨ `llm_estimate/models/` ä¸­åˆ›å»ºæ–°çš„æ¨¡å‹ç±»
2. ç»§æ‰¿ `BaseModel` å¹¶å®ç°å¿…è¦æ–¹æ³•
3. åœ¨ `registry.py` ä¸­æ³¨å†Œæ–°æ¨¡å‹

### æ·»åŠ æ–°åŠ é€Ÿå™¨

1. åœ¨ `llm_estimate/hardware/accelerator.py` çš„ `ACCELERATOR_SPECS` ä¸­æ·»åŠ è§„æ ¼
2. æä¾›ç®—åŠ›ï¼ˆTFLOPSï¼‰ã€å†…å­˜å¸¦å®½ï¼ˆGB/sï¼‰ã€å†…å­˜å®¹é‡ï¼ˆGBï¼‰ç­‰å…³é”®å‚æ•°
3. å¯é€‰æ‹©æ€§æ·»åŠ åŠŸè€—ã€ä»·æ ¼ç­‰è¾…åŠ©ä¿¡æ¯

ç¤ºä¾‹ï¼š
```python
"new-accelerator": AcceleratorSpecs(
    name="New-Accelerator",
    manufacturer="Vendor",
    device_type="gpu",  # æˆ– "cpu", "tpu", "soc"
    compute_capability_tflops=100.0,
    memory_bandwidth_gb_s=1500.0,
    memory_capacity_gb=48.0,
    release_year=2024,
    price_usd=5000,
    power_consumption_w=400
)
```

## è¾“å‡ºç¤ºä¾‹

```
=== æ€§èƒ½ä¼°ç®— ===
æ¨¡å‹: qwen3-8b
åŠ é€Ÿå™¨: RTX-4090
ç²¾åº¦: fp16
æ‰¹æ¬¡å¤§å°: 1
è¾“å…¥é•¿åº¦: 1024
è¾“å‡ºé•¿åº¦: 256

=== æ ¸å¿ƒæŒ‡æ ‡ ===
â€¢ TTFT (é¦–Tokenæ—¶é—´): 45.2 ms
â€¢ TPOT (æ¯Tokenæ—¶é—´): 18.7 ms
â€¢ æ€»å»¶è¿Ÿ: 4.83 s
â€¢ ååé‡: 265 tokens/s
â€¢ å†…å­˜ä½¿ç”¨: 14.8 GB
â€¢ ç“¶é¢ˆ: memory_bandwidth (89% åˆ©ç”¨ç‡)

=== æ€§èƒ½åˆ†æ ===
â€¢ è®¡ç®—åˆ©ç”¨ç‡: 72%
â€¢ å†…å­˜å¸¦å®½åˆ©ç”¨ç‡: 89%
â€¢ å†…å­˜å®¹é‡åˆ©ç”¨ç‡: 62%
```

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼ 